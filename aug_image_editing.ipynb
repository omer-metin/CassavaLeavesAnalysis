{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "designed-glass",
   "metadata": {},
   "source": [
    "# Classification of Cassava Leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-exposure",
   "metadata": {},
   "source": [
    "## 1. Creating Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-ballot",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "distant-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # for path operations\n",
    "import pickle  # for saving and loading created data\n",
    "\n",
    "import cv2  # for reading images\n",
    "import pandas as pd  # for reading and using image and label data\n",
    "import numpy as np  # for the matrix operations\n",
    "from sklearn.model_selection import train_test_split  # for splitting data to train and test sets\n",
    "from tensorflow.keras.layers.experimental import preprocessing  # for augmentation operations of images\n",
    "from tensorflow.keras.models import Sequential  # for augmentation layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-sucking",
   "metadata": {},
   "source": [
    "### Definiation of augmentation paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tamil-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2  # test/train data split ratio\n",
    "IMG_W, IMG_H, CHAN = 200, 200, 3  # output image dimensions 200x200 pixels and 3 color channels as RGB\n",
    "sample_count = 4000  # number to determine how much sample will be included for each class\n",
    "\n",
    "# below paths should be edit  \n",
    "input_data_path = \"\"  # this directory must contain train.csv, train_images(dir)\n",
    "                      # \"../input/cassava-leaf-disease-classification\" for running on kaggle\n",
    "output_data_path = \"\"  # this directory will be used for training phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-pathology",
   "metadata": {},
   "source": [
    "### Creation of augmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "comprehensive-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for images will be created by augmentation\n",
    "aug_rotate = Sequential([preprocessing.Resizing(IMG_H, IMG_W),\n",
    "                         preprocessing.RandomRotation(factor=1.0),\n",
    "                         preprocessing.Rescaling(1./255)])\n",
    "\n",
    "# model for modifing original images\n",
    "aug_norm = Sequential([preprocessing.Resizing(IMG_H, IMG_W),\n",
    "                       preprocessing.Rescaling(1./255)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-question",
   "metadata": {},
   "source": [
    "### Reading the label and image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mediterranean-conclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label distribution: [1087, 2189, 2386, 13158, 2577]\n",
      "\n",
      "             image_id  label  augment\n",
      "0      1000015157.jpg      0    False\n",
      "7      1001320321.jpg      0    False\n",
      "18     1003888281.jpg      0    False\n",
      "73     1012426959.jpg      0    False\n",
      "109    1018973237.jpg      0    False\n",
      "...               ...    ...      ...\n",
      "12504  3241388791.jpg      4     True\n",
      "6677   2195289519.jpg      4     True\n",
      "4439   1792460758.jpg      4     True\n",
      "16239  3924666081.jpg      4     True\n",
      "1973   1347999958.jpg      4     True\n",
      "\n",
      "[20000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(input_data_path, \"train.csv\"))  # read raw data\n",
    "counts = [np.count_nonzero(df['label'] == i) for i in range(5)]  # calculate label counts\n",
    "print(f\"original label distribution: {counts}\\n\")\n",
    "\n",
    "# selection of augmentation needed labels and images will be augmented\n",
    "sample = None\n",
    "for i in range(5):\n",
    "    if sample_count <= counts[i]:\n",
    "        sample = sample.append(df[df['label'] == i].sample(n=sample_count))\n",
    "        continue\n",
    "    if sample is None:\n",
    "        sample = df[df['label'] == i]\n",
    "    else:\n",
    "        sample = sample.append(df[df['label'] == i])\n",
    "    sample = sample.append(df[df['label'] == i].sample(\n",
    "        n=sample_count-counts[i], replace=True))\n",
    "sample['augment'] = sample.duplicated()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-milan",
   "metadata": {},
   "source": [
    "### Splitting dataframe to train and test entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "attached-upgrade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             image_id  label  augment\n",
      "18890    52883488.jpg      1     True\n",
      "21098   939773003.jpg      4    False\n",
      "2570   1447330096.jpg      2    False\n",
      "1634   1286409959.jpg      1    False\n",
      "3249   1563395006.jpg      2    False\n",
      "...               ...    ...      ...\n",
      "13046  3337851974.jpg      1     True\n",
      "19629   664996949.jpg      3    False\n",
      "3243    156209433.jpg      1    False\n",
      "3664   1649683387.jpg      1     True\n",
      "7794   2386015135.jpg      2    False\n",
      "\n",
      "[16000 rows x 3 columns]\n",
      "             image_id  label  augment\n",
      "15043  3702249794.jpg      1     True\n",
      "7570    234859800.jpg      3    False\n",
      "5595   1994597996.jpg      1    False\n",
      "11400  3035716224.jpg      4    False\n",
      "2785   1484094890.jpg      0    False\n",
      "...               ...    ...      ...\n",
      "19457   632445353.jpg      3    False\n",
      "4091    173019618.jpg      1    False\n",
      "3126   1541989559.jpg      0     True\n",
      "12818  3295550498.jpg      1     True\n",
      "20443   813217011.jpg      4    False\n",
      "\n",
      "[4000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(sample, test_size=test_split)\n",
    "print(df_train, df_test, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-construction",
   "metadata": {},
   "source": [
    "### Creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "reasonable-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...499/16000\n",
      "processing...999/16000\n",
      "processing...1499/16000\n",
      "processing...1999/16000\n",
      "processing...2499/16000\n",
      "processing...2999/16000\n",
      "processing...3499/16000\n",
      "processing...3999/16000\n",
      "processing...4499/16000\n",
      "processing...4999/16000\n",
      "processing...5499/16000\n",
      "processing...5999/16000\n",
      "processing...6499/16000\n",
      "processing...6999/16000\n",
      "processing...7499/16000\n",
      "processing...7999/16000\n",
      "processing...8499/16000\n",
      "processing...8999/16000\n",
      "processing...9499/16000\n",
      "processing...9999/16000\n",
      "processing...10499/16000\n",
      "processing...10999/16000\n",
      "processing...11499/16000\n",
      "processing...11999/16000\n",
      "processing...12499/16000\n",
      "processing...12999/16000\n",
      "processing...13499/16000\n",
      "processing...13999/16000\n",
      "processing...14499/16000\n",
      "processing...14999/16000\n",
      "processing...15499/16000\n",
      "processing...15999/16000\n"
     ]
    }
   ],
   "source": [
    "train_output = np.zeros([len(df_train), IMG_H, IMG_W, CHAN], dtype=np.float32)  # image data container\n",
    "train_labels = np.zeros([len(df_train)], dtype=np.uint8)  # label data container\n",
    "\n",
    "for idx, (image_id, label, aug) in enumerate(df_train.values):  # iteration over training dataframe\n",
    "    train_labels[idx] = label  # save label\n",
    "    im = cv2.imread(os.path.join(input_data_path, \"train_images\", image_id))  # reading image\n",
    "    \n",
    "    if aug:\n",
    "        train_output[idx] = aug_rotate(np.array([im]))  # if image is not original, it will be augmented\n",
    "    else:\n",
    "        train_output[idx] = aug_norm(np.array([im]))  # if image is original image, resizing and rescaling enough\n",
    "    \n",
    "    if (idx + 1) % 500 == 0:\n",
    "        print(f\"processing...{idx}/{len(df_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-worcester",
   "metadata": {},
   "source": [
    "### Stroring training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "inside-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image data is saved as: C:/users/omer/desktop/demo_data\\train_data/aug_200x200x3\\train.pickle\n",
      "train label data is saved as: C:/users/omer/desktop/demo_data\\train_data/aug_200x200x3\\label.pickle\n"
     ]
    }
   ],
   "source": [
    "train_data_path = os.path.join(output_data_path, f\"train_data/aug_{IMG_W}x{IMG_H}x{CHAN}\")  # path to save training data\n",
    "if not os.path.isdir(train_data_path):\n",
    "    os.makedirs(train_data_path)  # create directory if not exist\n",
    "\n",
    "with open(os.path.join(train_data_path, \"train.pickle\"), \"wb\") as f:  # storing train image data \n",
    "    pickle.dump(train_output, f, protocol=4)\n",
    "    print(f\"train image data is saved as: {os.path.join(train_data_path, 'train.pickle')}\")\n",
    "\n",
    "with open(os.path.join(train_data_path, \"label.pickle\"), \"wb\") as f:  # storing train label data\n",
    "    pickle.dump(train_labels, f)\n",
    "    print(f\"train label data is saved as: {os.path.join(train_data_path, 'label.pickle')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-bridge",
   "metadata": {},
   "source": [
    "### Creating testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "retired-fiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...499/4000\n",
      "processing...999/4000\n",
      "processing...1499/4000\n",
      "processing...1999/4000\n",
      "processing...2499/4000\n",
      "processing...2999/4000\n",
      "processing...3499/4000\n",
      "processing...3999/4000\n"
     ]
    }
   ],
   "source": [
    "test_output = np.zeros([len(df_test), IMG_H, IMG_W, CHAN], dtype=np.float32)\n",
    "test_labels = np.zeros([len(df_test)], dtype=np.uint8)\n",
    "\n",
    "for idx, (image_id, label, aug) in enumerate(df_test.values):  # iteration over test dataframe\n",
    "    test_labels[idx] = label\n",
    "    im = cv2.imread(os.path.join(input_data_path, \"train_images\", image_id))  # reading image\n",
    "    if aug:\n",
    "        test_output[idx] = aug_rotate(np.array([im]))  # if image is not original, it will be augmented\n",
    "    else:\n",
    "        test_output[idx] = aug_norm(np.array([im]))  # if image is original image, resizing and rescaling enough\n",
    "    if (idx + 1) % 500 == 0:\n",
    "        print(f\"processing...{idx}/{len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-mexico",
   "metadata": {},
   "source": [
    "### Storing testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "beautiful-pickup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test image data is saved as: C:/users/omer/desktop/demo_data\\test_data/aug_200x200x3\\test.pickle\n",
      "test label data is saved as: C:/users/omer/desktop/demo_data\\test_data/aug_200x200x3\\label.pickle\n"
     ]
    }
   ],
   "source": [
    "test_data_path = os.path.join(output_data_path, f\"test_data/aug_{IMG_W}x{IMG_H}x{CHAN}\")  # path to save testing data\n",
    "if not os.path.isdir(test_data_path):\n",
    "    os.makedirs(test_data_path)  # create directory if not exist\n",
    "\n",
    "with open(os.path.join(test_data_path, \"test.pickle\"), \"wb\") as f:  # storing test image data\n",
    "    pickle.dump(test_output, f, protocol=4)\n",
    "    print(f\"test image data is saved as: {os.path.join(test_data_path, 'test.pickle')}\")\n",
    "\n",
    "with open(os.path.join(test_data_path, \"label.pickle\"), \"wb\") as f:  # storing test label data\n",
    "    pickle.dump(test_labels, f)\n",
    "    print(f\"test label data is saved as: {os.path.join(test_data_path, 'label.pickle')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-compiler",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
